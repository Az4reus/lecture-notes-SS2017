# Overview, GAD 05/31
In this Lecture, we.... 

# Content
Continuiation of sorting algorithms. 

## Insertion sort
Pick element, insert in proper place. 

```c
void insertionSort(Element[] a, int n) {
  for (int i = 1; i < n; i++) {
    for(int j = i-1; j >= 0; j--) {
      if (a[j] > a[j+1]) {
        swap(a,j,j+1)
      }
    }
  }
}
```

Zeitaufwand: 

- Einfuegung des i-ten Elemnts an richtiger stelle: $O(i)$
- Gesamtzeit: $\sum^n_{i=1} O(i) = O(n^2)$
- Vorteil: einfach zu implementieren
- Nachteil: quadratische Laufzeit. 

## Merge Sort
Zerlege due Eingabesequenz rekursiv in teile, die separat sortiert und dann zur
Ausgabesequenz verschmolzen werden. 

```c
void mergeSort(Element[] a, int l, int r) {
  if (l==r) return; 
  m = floor((r+l)/2);
  mergeSort(a, l, m); 
  mergeSort(a, m+1, r); 
  j = l; 
  l = m + 1; 
  for (i = 0; i <= r - l; i++){
    if (j > m) { b[i] = a[k]; k++; }
    else {
      if( k > r) { b[i] = a[j]; j++; }
      else { 
        if( a[j] <= a[k]) { b[i] = a[j]; j++; }
        else { b[i] = a[k]; k++; }
      }
    }
  }
  for (i = 0, i <= r - l; i++) { a[l+i] = b[i]; }
```

Zeitaufwand: 

- T(n): Laufzeit bei Feldgroesse n
- T(1) = $\Theta(1)$
- $T(n) \in O(n\log n) \Rightarrow$ folgt aus dem sog. Master-Theorem

## Analyse rekursiver Funktionen

- nichtrekurisve Unterprogrammaufrufe sind einfach zu analysieren. 
- Rekursive Aufrufstrukturen liefern **Rekursionsgleichungen**. 
- $\Rightarrow$ Funktionswert wird in Abhaengigkeit von Funktionerswerten fuer
  kleiner Argumente bestimmt.  
  gesucht: nicht-rekursive/geschlossene Form. 

Anwendung: **Divide-and-Conquer** Algorithmen

- gegeben: Problem der Groesse $n=b^k (k\in \mathbb{N}_0)$
- falls $k \geq 1$: 
    - zerlege das Problem in $d$ Teilprobleme der Groesse $n/b$
    - loese die Teilprobleme ($d$ rekursive Aufrufe) 
    - setze aus den Teilloesungen die Loesung zusammen
- falls $k=0$ bzw. $n=1$: invesierte Aufwand $a$ zur Loesung. 


- Betrachte den Aufwand fuer jede Rekursionstiefe
- Anfang: Problemgroesse $n$ 
- Level fuer Rekursionstiefe $i$: $d^i$ Teilprobleme der Groesse $n/b^i$,
  unbekannter Aufwand $c$.
- $\Rightarrow$ Gesamtaufwand auf Rekursionslevel $i$: 
  $$d^ic\frac{n}{b^i} = cn (\frac{d}{b})^i$$
  Die *geometrische Reihe*
    - $d < b$: Aufwand sinkt mit wachsender Rekursionstiefe, **erstes** Level
      entspricht konstantem Anteil des Gesamtaufwands
    - $d=b$ Gesamtaufwand fuer jedes Level gleich gross, maximale
      Rekursionstiefe logarithmuch, Gesamtaufwand $\Theta(n\log n)$
    - $d>b$ Aufwand steigt mit wachsender Rekursionstiefe, **letztes** Level
      entspricht konstantem Anteil des Gesamtaufwandes. 

This leads to the following levels: 

- Level 0: 1 Problem der Groesse $n=b^k$
- Level $i$: $d^i$ Probleme der Groesse $n/b^i = n^{k-i}$
- Level $k$: $d^k$ Probleme der Groesse $n/b^k = b^{k-k} = 1$, hier mit Kosten
  $a$, also Kosten $ad^k$ 
- $d=b$: Kosten $ad6k = ab^k = an \in \Theta(n)$ auf Level $k$ , $cnk =
  cn\log_bn \in \Theta(n\log n)$ 
- $d<b$: Kosten $ad^k < ab^k = an \in \Theta(n)$  auf Level $k$, rest: 
  $$cn\sum^{k=1}_{i=0}(\frac{d}{b})^i = cn\frac{1-(d/b)6k}{1-d/b} <
  cn\frac{1}{1-d/b} \in O(n) > cn \in \Omega(n)\Rightarrow \Theta(n)$$
- $d>b$: _(insert math here)_, result: $\Theta(n^{\log_b d})$

## Vereinfachtes Master-Theorem
Seien $a,b,c,d$ positive Konstanten und $n=b^k$, mit $k\in\mathbb{N}$. 
Betrachte die folgende Rekursionsgleichung:
$$ r(n) = \begin{cases} a & \text{falls } n=1 \\ cn+d\cdot r(n/b) & \text{falls
} n > 1 \end{cases}$$ 
Dann gilt: 
$$ r(n) = \begin{cases} \Theta(n) & \text{falls } d < b \\ \Theta(n \log n) &
\text{falls } d=b \\ \Theta(n^{\log_b d}) & \text{falls } d>b \end{cases}$$ 
