# Overview, GAD, 04-26
In this lecture, 

## Content

### Bresenham Algorithm, reprise.
```python
def draw_circle(radius): 
  x = 0
  y = radius

  plot(0, radius) # Draw initial 4, mirrored points. 
  plot(radius, 0)
  plot(0, -radius) 
  plot(-radius, 0)

  f = 1 - radius
  de = 1
  dse = 2 - radius - radius

  while x < y: # loop over radius, pixel by pixel
    if f < 0: 
      f += de
      dse += 2
    else: 
      f += dse
      y -= 1
      dse += 4

    x += 1
    de += 2

    plot(x,y); plot(-x,y); plot(-y,x); plot(-y,-x) # Draw to mirrored lines.
    plot(y,x); plot(y,-x); plot(x,-y); plot(-x,-y)
```

This draws a pixelated circle without using any numeric operation other than 
integer addition. Still in use today, too. 

### Complexity analysis. 

Goals for measuring efficiency: 

 - Description of performance of an algorithm
 - as concise and precise as possible. 

The exact specification of the performance of an algorithm can be written $T: I \to \mathbb{N}$,
where $I$ is the set of instances of the algorithm (each different set of inputs
forms its own _Instance_ of the algorithm)
The issue with this is that $T$ is very hard, if not impossible to determine.
The solution is to _group_ instances, usually by size. (This meaning, grouping 
by size of input for a sorting algorithm, or length of numbers passed into multiplication)

### Input encoding
When looking at the _size_ of input, be careful with encoding it.  

For example the prime factors of a number $x \in \mathbb{N}$. This is an NP-hard
problem, which is important for encryption. 

The Trivial Algorithm for finding the prime factors of a number consists of
looking at numbers $1 \dots \sqrt{x}$ and seeing if they divide $x$. This takes,
at most, $\log_2 x$ divisions.

Now, if you encode $x$ unary, meaning you just put 1s into a row until you have a row 
where `len(x) == x` (so $x$ 1s), this computation takes polynomial time.

However, if you are to encode $x$ in binary, as computers do, the computation will
take exponential time, because $\log_2x$ bits are required to encode $x$. 

This is not magic, the perceived sudden inefficiency of encoding things in binary
is already negated by the inefficient presentation that is unary encoding. 

### Measurements of efficiency. 
Let $I_n$ be the instaces of size $n$ of the problem. 

Measurements are: 

- Worst case: $t(n) = max \{ T(i) : i \in I_n \}$
- Best case: $t(n) = min \{ T(i) : i \in I_n\}$
- Average case: $t(n) = \frac{1}{|I_n|}\sum_{i\in I_n}T(i)$

These end up being comparable figures that let you estimate the rough cost of an 
algorithm. 

## Definitions
- **Instance of an algorithm**:  
  Each set of possible input values to the algorithm forms an instance of the algorithm. 
  `sum(1,1)` and `sum(1,2)` form two instances of sum, for example. These are then usually 
  grouped by size of input, for example length of numbers. 
